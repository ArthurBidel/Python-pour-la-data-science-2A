{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table des matières\n",
    "\n",
    "* [Codes supplémentaires](#section1)\n",
    "    * [Multi-Threading](#section11)\n",
    "    * [xxx](#section12)\n",
    "* [Nettoyage des données de Légifrance](#section2)\n",
    "    * [xxx](#section21)\n",
    "* [Sauvegarde des tableaux de données finalisées](#section3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codes supplémentaires<a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section seront regroupés tous les codes qui ont été faits, mais qui ne sont finalement pas intégrés au projet final. Nous les avons mis car ils sont intéressants, car explorant d'autre méthodes par exemple, et sont en lien avec le projet, donc pourraient servir à l'avenir dans des projets similaires. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Threading <a class=\"anchor\" id=\"section11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de nos tentatives de récupération des données via l'API Piste, une méthode envisagée fût de récupérer les fichiers sur des pages de de taille 1, car cela semblait fonctionner au delà du 10001e éléments. Ainsi pour pallier les contraintes de temps du projet nous avons codé de quoi faire simultanément les récupération de données en multi-threading. \n",
    "\n",
    "L'idée est donc de calculer le nombre de pages restantes pour la requête souhaitée, puis en donnant le nombre de threads souhaités produire le même nombre de fonctions. Ces fonctions récupéreront les données sur des plages de pages de tailles similaires, les plages correspondent environ au ratio de pages restantes par rapport aux nombres de fonctions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaining_page_number(file_name):\n",
    "    '''\n",
    "    Calcule le nombre de pages restantes à récupérer en comparant le nombre total de résultats et la progression sauvegardée dans un fichier spécifique.\n",
    "\n",
    "    :param file_name: Nom du fichier JSON utilisé pour sauvegarder la progression (sans l'extension).\n",
    "    :return: Le nombre de pages restantes à récupérer à partir de la progression sauvegardée.\n",
    "    '''\n",
    "    api_host = API_HOST+\"/search\"\n",
    "    client = get_client()\n",
    "    response = client.post(api_host, json=code_api).json()\n",
    "    total_results = response.get(\"totalResultNumber\", 0)\n",
    "    file_name = str(file_name)+\".json\"\n",
    "    try:\n",
    "        # Charger les données existantes si le fichier existe\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "            existing_data = json.load(file)\n",
    "            if not isinstance(existing_data, dict):\n",
    "                raise ValueError(\"Le fichier de sauvegarde n'est pas correctement structuré.\")\n",
    "            start_page = existing_data.get(\"current_page\", 1)\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        start_page = 0\n",
    "    remaining_page = total_results-start_page\n",
    "    return remaining_page    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_results_between(api_host, code, page_to_start, page_to_end, thread_number):\n",
    "    '''\n",
    "    Récupère les résultats d'une requête API sur une plage spécifique de pages.\n",
    "\n",
    "    :param api_host: Adresse du serveur où envoyer la requête avec le endpoint correspondant.\n",
    "    :param code: Code de la requête en json\n",
    "    :param page_to_start: Numéro de la première page à récupérer dans la plage.\n",
    "    :param page_to_end: Numéro de la dernière page à récupérer dans la plage.\n",
    "    :param thread_number: Numéro du thread utilisé pour différencier les fichiers de sauvegarde.\n",
    "    :return: Aucun retour direct, les résultats sont sauvegardés dans un fichier JSON.\n",
    "    '''\n",
    "\n",
    "    client = get_client()\n",
    "    expires_in = 55*60\n",
    "    token_expiry = datetime.now() + timedelta(seconds=expires_in)\n",
    "\n",
    "    file_name = str(thread_number)+\"results.json\"\n",
    "\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for page_number in range(page_to_start, page_to_end + 1):\n",
    "        # Vérifier si le token doit être renouvelé\n",
    "        if datetime.now() >= token_expiry:\n",
    "            print(\"Renouvellement du client OAuth...\")\n",
    "            client = get_client()\n",
    "            token_expiry = datetime.now() + timedelta(seconds=expires_in)\n",
    "\n",
    "        print(f\"Récupération de la page {page_number}/{page_to_end - page_to_start +1}...\")\n",
    "        code[\"recherche\"][\"pageNumber\"] = page_number\n",
    "        response = client.post(api_host, json=code).json()\n",
    "        page_results = response.get(\"results\", [])\n",
    "\n",
    "        if response.get(\"error\") == 503:\n",
    "            print(response)\n",
    "            break\n",
    "\n",
    "        if page_number % 10 == 0: \n",
    "            print(response)\n",
    "\n",
    "        # Ajouter les résultats de la page courante\n",
    "        all_results.extend(page_results)\n",
    "\n",
    "        # Sauvegarder les résultats toutes les 20 pages ou à la dernière page\n",
    "        if page_number % 20 == 0 or page_number == page_to_end:\n",
    "            print(f\"Ajout des pages jusqu'à la page {page_number} dans {file_name}...\")\n",
    "            save_results_to_file(all_results, file_name, page_number)\n",
    "\n",
    "            # Réinitialiser la liste des résultats sauvegardés\n",
    "            all_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_functions(n, file_name):\n",
    "        '''\n",
    "        Génère un ensemble de fonctions pour récupérer des pages de résultats en parallèle.\n",
    "\n",
    "        :param n: Nombre de threads ou de fonctions à générer.\n",
    "        :param file_name: Nom du fichier JSON utilisé pour sauvegarder la progression (sans l'extension).\n",
    "        :return: Un dictionnaire contenant les fonctions générées, prêtes à être exécutées pour traiter une plage de pages.\n",
    "        '''\n",
    "\n",
    "        api_host = API_HOST+\"/search\"\n",
    "        client = get_client()\n",
    "        remaining_page = remaining_page_number(file_name)\n",
    "        functions = {}\n",
    "        file_name = str(file_name)+\".json\"\n",
    "        response = client.post(API_HOST+\"/search\", json=code_api).json()\n",
    "        total_results = response.get(\"totalResultNumber\", 0)\n",
    "        try:\n",
    "            with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "                existing_data = json.load(file)\n",
    "                if not isinstance(existing_data, dict):\n",
    "                    raise ValueError(\"Le fichier de sauvegarde n'est pas correctement structuré.\")\n",
    "                start_page = existing_data.get(\"current_page\", 1)\n",
    "        except (FileNotFoundError, ValueError):\n",
    "            start_page = 1\n",
    "\n",
    "        page_state = [start_page, start_page]\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            if i != n : \n",
    "                    page_to_end = [int(np.floor(remaining_page*i/n)+ page_state[1])]\n",
    "            else : \n",
    "                    page_to_end = [total_results]\n",
    "\n",
    "            thread_number = i\n",
    "\n",
    "            def func_template(idx=i, start=page_state[0], end=page_to_end[0], thread_nbr= thread_number):\n",
    "                collect_all_results_between(API_HOST+\"/search\", code_api, start, end, thread_nbr)\n",
    "\n",
    "            page_state[0]= page_to_end[0] + 1\n",
    "                \n",
    "            functions[f\"f_{i}\"] = func_template\n",
    "        return functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functions_to_thread(n, file_name):\n",
    "    '''\n",
    "    Prépare une liste de fonctions générées avec leurs arguments pour une exécution dans des threads.\n",
    "\n",
    "    :param n: Nombre de threads ou de fonctions à générer.\n",
    "    :param file_name: Nom du fichier JSON utilisé pour sauvegarder la progression (sans l'extension).\n",
    "    :return: Une liste de tuples contenant les fonctions générées, leurs arguments (liste vide), et leurs mots-clés (dictionnaire vide).\n",
    "    '''\n",
    "\n",
    "    generated_functions = generate_functions(n, file_name)\n",
    "    functions = [(generated_functions[f\"f_{i}\"], [], {}) for i in range(1, n+1) ]\n",
    "    return functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_in_threads(functions):\n",
    "    '''\n",
    "    Exécute un ensemble de fonctions dans des threads distincts.\n",
    "\n",
    "    :param functions: Liste de tuples contenant les fonctions à exécuter, leurs arguments (sous forme de liste), et leurs mots-clés (sous forme de dictionnaire).\n",
    "    :return: Aucun retour direct. Les threads sont lancés et exécutés, puis attendus jusqu'à leur complétion.\n",
    "    '''\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    for func, args, kwargs in functions:\n",
    "        thread = Thread(target=func, args=args, kwargs=kwargs)\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Attendre la fin de tous les threads\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
