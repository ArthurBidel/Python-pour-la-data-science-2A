{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de données répertoriant les indicateurs de délinquance et de criminalité (1996-2022 en France)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sommaire\n",
    "\n",
    "* [Récupération et nettoyage des données du Ministère de l'Intérieur](#section1)\n",
    "* [Conception des indicateurs de délinquance et criminalité](#section2)\n",
    "    * [Ajout des estimations de population](#section21)\n",
    "    * [Calcul des taux](#section22)\n",
    "    * [Autres variables adjacentes](#section23)\n",
    "* [Ajout de variables de contrôle pour une future modélisation](#section3)\n",
    "    * [Densité urbaine (Table départementale)](#section31)\n",
    "    * [Evolution du taux de pauvreté (Table nationale)](#section32)\n",
    "* [Sauvegarde des tableaux de données finalisés](#section4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération et nettoyage des données du Ministère de l'Intérieur relative aux crimes et délits<a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(NB : Les liens hypertextes présents dans ce markdown et les suivants renvoient aux sites internet sur lesquels les tableaux de données ont été téléchargés et ne correspondent pas aux URL de téléchargement, l'exécution des cellules de code permet de télécharger automatiquement les jeux de données)\n",
    "\n",
    "Nous avons récupéré, grâce à l'open data du ministère de l'intérieur ([ici](https://www.data.gouv.fr/fr/datasets/chiffres-departementaux-mensuels-relatifs-aux-crimes-et-delits-enregistres-par-les-services-de-police-et-de-gendarmerie-depuis-janvier-1996/)) les données relatives aux crimes et délits enregistrés dans chaque département et en France entre janvier 1996 et août 2022. Ce jeu de données a été produit successivement par le Ministère de l'Intérieur puis par le SSMSI depuis sa création en 2014. \n",
    "\n",
    "Issu directement des applications informatiques de gestion, il n'est pas retraité et reste assez brut. Entre autres, il ne nous donne accès qu'au nombre d'infractions (classées par type) par département, nous l'avons donc complété avec des données d'estimation de population pour obtenir des taux d'infractions plutôt que des chiffres bruts. Nous avons ensuite ajouté à notre base de données des indices de localisation pour nous permettre de réaliser des représentations géographiques dans notre partie de statistiques descriptives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, zipfile\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import s3fs\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de téléchargement du fichier\n",
    "url = \"https://static.data.gouv.fr/resources/chiffres-departementaux-mensuels-relatifs-aux-crimes-et-delits-enregistres-par-les-services-de-police-et-de-gendarmerie-depuis-janvier-1996/20221031-102847/tableaux-4001-ts.xlsx\" \n",
    "\n",
    "# Dossier de destination pour enregistrer le fichier téléchargé\n",
    "dossier_destination = \"data\"\n",
    "os.makedirs(dossier_destination, exist_ok=True)\n",
    "\n",
    "# Chemin du fichier téléchargé\n",
    "fichier_telecharge = os.path.join(dossier_destination, \"fichier.xlsx\")\n",
    "\n",
    "# Téléchargement du fichier\n",
    "print(\"Téléchargement en cours...\")\n",
    "response = requests.get(url, stream=True)\n",
    "with open(fichier_telecharge, \"wb\") as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "print(\"Téléchargement terminé:\", fichier_telecharge)\n",
    "\n",
    "# Chargement des onglets du fichier Excel en DataFrames\n",
    "print(\"Chargement des onglets dans des DataFrames...\")\n",
    "data = pd.read_excel(fichier_telecharge, sheet_name=None)  # `sheet_name=None` charge tous les onglets\n",
    "\n",
    "# Fusion des onglets dans un unique DataFrame avec une colonne pour identifier le département (ou la zone)\n",
    "données_police = pd.concat(\n",
    "    [df.assign(Zone=nom_onglet) for nom_onglet, df in data.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Suppression du fichier téléchargé \n",
    "os.remove(fichier_telecharge)\n",
    "print(\"Fichier téléchargé supprimé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare notre premier jeu de données (données police) en deux pour obtenir une base de données départementale et une base nationale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données pour la france entière\n",
    "df_nat = données_police[données_police['Zone'].isin(['France_Entière', 'France_Métro'])]\n",
    "\n",
    "# Données départementales\n",
    "df_dep = données_police[~données_police['Zone'].isin(['France_Entière', 'France_Métro'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le format des tableaux de données actuel indique les dates en tant que variable (colonne) tandis que chaque ligne correspond à un type d'infraction. Les valeurs sont des occurrences (voir ci-dessous). \n",
    "\n",
    "| Index  | Libellé | Zone | _2022_08 | _2022_07 | ... | _1996_01 |\n",
    "|-----------|----------|----------|----------|----------|----------|----------|\n",
    "| Type 1    | Libellé  1 | France | Valeur 1 | Valeur 3 | Valeur 5 | Valeur 8 |\n",
    "| Type 2    | Libellé  2 | France | Valeur 2 | Valeur 4 | Valeur 6 | Valeur 9 |\n",
    "\n",
    "Nous préférions avoir une colonne indiquant la date car il nous semblait plus simple de filtrer par date et d'ajouter de nouvelles colonnes d'information ainsi (exemple ci-dessous). Ainsi, chaque ligne correspond à un incident.\n",
    "\n",
    "| Index | Libellé | Zone | Date |\n",
    "|-------|---------|------|------|\n",
    "| Type 1 | Libellé 1 | Zone a | _2022_08 |\n",
    "| Type 2 | Libellé 2 | Zone a | _2022_08 |\n",
    "| ... | ... | ... | ... |\n",
    "| Type 1 | Libellé 1 | Zone f | _2012_05 |\n",
    "| ... | ... | ... | ... |\n",
    "| Type 34 | Libellé 34 | Zone z | _1996_01 |\n",
    "\n",
    "Nous avons donc restructuré les deux tableaux de données en format long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer le tableau (échelle nationale) en format \"long\"\n",
    "df_nat = df_nat.melt(id_vars=['Index', 'libellé index', 'Zone'],  # Colonnes fixes\n",
    "                  var_name='Date',  # Nom pour la colonne de dates\n",
    "                  value_name='Nombre')  # Nom pour la colonne des valeurs\n",
    "\n",
    "# Transformer le tableau (échelle départementale) en format \"long\"\n",
    "df_dep = df_dep.melt(\n",
    "    id_vars=['Index', 'libellé index', 'Zone'],  # Colonnes fixes\n",
    "    var_name='Date',  # Nom pour la colonne de dates\n",
    "    value_name='Nombre'  # Nom pour la colonne des valeurs\n",
    ")\n",
    "#On renomme la colonne 'Zone' en 'Département'\n",
    "df_dep = df_dep.rename(columns={'Zone': 'Département'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de l'existence de doublons \n",
    "if df_dep.duplicated().any():\n",
    "    print(\"Des doublons existent dans la base départementale.\")\n",
    "else:\n",
    "    print(\"Aucun doublon trouvé dans la base nationale.\")\n",
    "\n",
    "if df_nat.duplicated().any():\n",
    "    print(\"Des doublons existent dans le DataFrame.\")\n",
    "else:\n",
    "    print(\"Aucun doublon trouvé dans le DataFrame.\")\n",
    "\n",
    "# Vérification de l'existence de valeurs manquantes\n",
    "valeurs_manquantes_dep = df_dep[df_dep.isna().any(axis=1)]\n",
    "print(f\"Nombre de lignes avec des valeurs manquantes dans la base départementale: {len(valeurs_manquantes_dep)}\")\n",
    "print(f\"Départements concernés :{valeurs_manquantes_dep[\"Département\"].unique()}\")\n",
    "\n",
    "valeurs_manquantes_nat = df_nat[df_nat.isna().any(axis=1)]\n",
    "print(f\"Nombres de lignes avec des valeurs manquantes dans la base nationale: {len(valeurs_manquantes_nat)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucun doublon n'est présent dans les données récupérées du Ministère de l'Intérieur (il était indiqué sur data.gouv.fr que c'était une éventualité). En revanche, les données concernant les territoires d'outre-mer ne sont pas disponibles avant une certaine date, nos deux DataFrames ont donc des valeurs manquantes, pour les départements concernés dans la base départementale et dans la catégorie France_Entière pour la base nationale. \n",
    "\n",
    "Comme les données (de population, densité, pauvreté etc.) ajoutées ensuite dans les bases présentaient elles aussi des manquements pour les territoires d'outre-mer, nous avons décidé de les exclure dès maintenant de nos bases de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des données hors métropole\n",
    "df_dep = df_dep[(df_dep['Département'] <= '95') | (df_dep['Département'].isin(['2A', '2B']))]\n",
    "\n",
    "df_nat = df_nat[df_nat['Zone'] != 'France_Entière']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conception des indicateurs de délinquance et de criminalité<a class=\"anchor\" id=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajout des estimations de population<a class=\"anchor\" id=\"section21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir les taux d'infractions, nous devons ajouter à nos deux tableaux de données, les estimations de population récupérées sur le site de l'INSEE à l'échelle nationale ([ici](https://www.insee.fr/fr/statistiques/serie/000436387#Tableau)) et départementale ([et là](https://catalogue-donnees.insee.fr/fr/explorateur/DS_ESTIMATION_POPULATION)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### Sur la table nationale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de téléchargement du fichier\n",
    "url = \"https://www.insee.fr/fr/statistiques/serie/telecharger/csv/000436387?ordre=antechronologique&transposition=donneescolonne&periodeDebut=1&anneeDebut=1996&periodeFin=8&anneeFin=2022&revision=sansrevisions\" \n",
    "\n",
    "# Dossier de destination\n",
    "destination = \"data/data_pop\"\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Chemin du fichier zip téléchargé\n",
    "fichier_zip = os.path.join(destination, \"fichier.zip\")\n",
    "\n",
    "# Téléchargement du fichier zip\n",
    "print(\"Téléchargement en cours...\")\n",
    "response = requests.get(url, stream=True)\n",
    "with open(fichier_zip, \"wb\") as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "print(\"Téléchargement terminé:\", fichier_zip)\n",
    "\n",
    "# Décompression du fichier zip\n",
    "print(\"Décompression en cours...\")\n",
    "with zipfile.ZipFile(fichier_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination)\n",
    "print(\"Décompression terminée.\")\n",
    "\n",
    "# Vérification des fichiers extraits\n",
    "fichiers = os.listdir(destination)\n",
    "print(\"Fichiers présents après décompression :\", fichiers)\n",
    "\n",
    "# Localisation et chargement du fichier valeurs_mensuelles.csv\n",
    "fichier_cible = os.path.join(destination, \"valeurs_mensuelles.csv\")\n",
    "if not os.path.exists(fichier_cible):\n",
    "    raise FileNotFoundError(\"Le fichier valeurs_mensuelles.csv n'a pas été trouvé.\")\n",
    "\n",
    "print(\"Chargement du fichier valeurs_mensuelles.csv en DataFrame...\")\n",
    "data_valeurs_mensuelles = pd.read_csv(fichier_cible, delimiter=';', encoding='utf-8') \n",
    "\n",
    "# Suppression des fichiers \n",
    "os.remove(fichier_zip)\n",
    "os.remove(os.path.join(destination, \"caractéristiques.csv\"))\n",
    "os.remove(os.path.join(destination, \"valeurs_mensuelles.csv\"))\n",
    "\n",
    "print(\"Processus terminé. Fichiers supprimés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes inutiles\n",
    "data_valeurs_mensuelles.drop(columns=['Codes'], inplace=True)\n",
    "\n",
    "# Suppression des trois premières lignes inutiles\n",
    "data_valeurs_mensuelles = data_valeurs_mensuelles.iloc[3:]\n",
    "data_valeurs_mensuelles.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Transformation du format de la colonne de date pour préparer l'inner join\n",
    "data_valeurs_mensuelles[\"Libellé\"] = data_valeurs_mensuelles[\"Libellé\"].str.replace(\"-\", \"_\").apply(lambda x: f\"_{x}\")\n",
    "\n",
    "# Renommer la colonne 'Démographie - Population au début du mois - France métropolitaine' car c'est bien trop long\n",
    "data_valeurs_mensuelles = data_valeurs_mensuelles.rename(columns={'Démographie - Population au début du mois - France métropolitaine': 'Population'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join sur les colonnes de date\n",
    "df_nat_bis = pd.merge(\n",
    "    df_nat,\n",
    "    data_valeurs_mensuelles,\n",
    "    left_on='Date',  # Colonnes de df_france\n",
    "    right_on='Libellé', # Colonnes de data_valeurs_mensuelles\n",
    "    how='inner'  # Type de jointure\n",
    ")\n",
    "\n",
    "#Les colonnes 'Date' et 'Libellé' sont identiques donc on supprime 'Libellé' (nom moins évocateurs)\n",
    "df_nat_bis = df_nat_bis.drop(columns=[\"Libellé\"])\n",
    "\n",
    "#Visualisation du résultat\n",
    "df_nat_bis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### Sur la table départementale :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrairement aux données nationales, les données départementales récupérées sont disponibles en open data avec une granularité annuelle et non pas mensuelle. On somme donc pour chaque année et chaque indicateur les nombres d'infractions pour ne conserver finalement que des données au premier janvier de chaque année. Si à l'avenir, on vient à utiliser des données mensuelles on tentera de linéariser les évolutions de population sur 12 mois. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire l'année \n",
    "df_dep['Année'] = df_dep['Date'].str.extract(r\"_(\\d{4})_\").astype(int)\n",
    "\n",
    "# Sommer les nombres d'infractions pour chaque année, département et type d'infraction\n",
    "df_dep_sum = df_dep.groupby(['Index', 'libellé index','Département', 'Année'], as_index=False)['Nombre'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de téléchargement du fichier\n",
    "url = \"https://api.insee.fr/melodi/data/DS_ESTIMATION_POPULATION/to-csv?maxResult=10000&SEX=_T&AGE=_T&TIME_PERIOD=1996&TIME_PERIOD=1997&TIME_PERIOD=1998&TIME_PERIOD=1999&TIME_PERIOD=2000&TIME_PERIOD=2001&TIME_PERIOD=2002&TIME_PERIOD=2003&TIME_PERIOD=2004&TIME_PERIOD=2005&TIME_PERIOD=2006&TIME_PERIOD=2007&TIME_PERIOD=2008&TIME_PERIOD=2009&TIME_PERIOD=2010&TIME_PERIOD=2011&TIME_PERIOD=2012&TIME_PERIOD=2013&TIME_PERIOD=2014&TIME_PERIOD=2015&TIME_PERIOD=2016&TIME_PERIOD=2017&TIME_PERIOD=2018&TIME_PERIOD=2019&TIME_PERIOD=2020&TIME_PERIOD=2021&TIME_PERIOD=2022&GEO=DEP&optionCsv=%7B%22format%22:%22csv%22,%22affichage%22:%22codes%22,%22decimales%22:%22point%22,%22periodeColonne%22:false,%22lang%22:%22fr%22%7D\" \n",
    "\n",
    "# Dossier de destination\n",
    "destination = \"data/data_pop\"\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Chemin du fichier zip téléchargé\n",
    "fichier_csv = os.path.join(destination, \"fichier_pop_dep.csv\")\n",
    "\n",
    "# Téléchargement du fichier zip\n",
    "print(\"Téléchargement en cours...\")\n",
    "response = requests.get(url, stream=True)\n",
    "with open(fichier_csv, \"wb\") as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "print(\"Téléchargement terminé:\", fichier_csv)\n",
    "\n",
    "# Vérification des fichiers extraits\n",
    "fichiers = os.listdir(destination)\n",
    "print(\"Fichiers présents après décompression :\", fichiers)\n",
    "\n",
    "print(\"Chargement du fichier en DataFrame...\")\n",
    "pop_dep = pd.read_csv(fichier_csv, delimiter=';', encoding='utf-8') \n",
    "\n",
    "# On garde une sauvegarde de ces données car la maintenance du site nous a plusieurs fois empêché de faire tourner le code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La maintenance du catalogue de données de l'INSEE nous a plusieurs fois empêché de faire tourner le code (la cellule précédente). On a donc conservé une sauvegarde de ce fichier (*fichier_pop_dep* dans ***data/data_pop***). En cas de problème d'exécution à ce niveau là, veuillez sortir la cellule suivante du mode commentaire et l'exécuter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fichier = \"data/data_pop/fichier_pop_dep.csv\"\n",
    "pop_dep = pd.read_csv(fichier, delimiter=';', encoding='utf-8') \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes non utilisées\n",
    "pop_dep.drop(columns=['GEO_OBJECT', 'SEX', 'AGE', 'OBS_STATUS_FR', 'EP_MEASURE'], inplace=True)\n",
    "\n",
    "# On renomme les colonnes pour faciliter l'inner join\n",
    "pop_dep = pop_dep.rename(columns={\n",
    "    'TIME_PERIOD': 'Année',\n",
    "    'GEO': 'Département',\n",
    "    'OBS_VALUE': 'Population'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inner join sur les tables de population et d'infractions départementales\n",
    "df_dep_bis = pd.merge(\n",
    "    df_dep_sum,\n",
    "    pop_dep,\n",
    "    on=['Département', 'Année'],  \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "#Visualisation du résultat\n",
    "df_dep_bis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcul des taux de délinquance et de criminalité<a class=\"anchor\" id=\"section22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tableaux traités ici comptent les 107 différentes catégories (index) d'infractions de \"l'état 4001\" enregistrées par les forces de sécurité. De nature, fréquence et variables de comptage variées, agglomérer ces index en un seul indicateur de délinquance est susceptible de masquer des phénomènes délinquants importants et, en effet, depuis 2012 le ministère de l'Intérieur a annoncé renoncer à l'utilisation d'indicateurs trop globaux. Aujourd'hui, une dizaine d'indicateurs sont utilisés par le SSMSI dans leurs bilans statistiques (le nombre peut varier selon la finesse de la typologie). On propose ici d'utiliser les 8 indicateurs principaux dénombrés dans le bilan statistique du SSMSI de 2013 ([téléchargeable ici](https://mobile.interieur.gouv.fr/Interstats/Actualites/Insecurite-et-delinquance-en-2023-bilan-statistique-et-atlas-departemental)), à savoir les *homicides*, *tentatives d'homicides*, *coups et blessures volontaires*, *violences sexuelles*, *atteintes aux biens avec violence contre les personnes*, *atteintes aux biens sans violence contre les personnes*, *infractions à la législation sur les stupéfiants* et *escroqueries*.\n",
    "\n",
    "Il est important de noter que les chiffres disponibles ici sont ceux de la criminalité observée et enregistrée qui reste un indicateur très imparfait. D'une part il ne reflète pas le nombre réel d'infractions, mais n'est pas non plus égal à une proportion de ce nombre constante dans le temps. Des décisions politiques et de gestion (comme la politique du chiffre à partir de 2002, les variations de moyens alloués aux forces de sécurité) peuvent impacter la part de la criminalité enregistrée par rapport à la criminalité effective. D'autre part cette partie observée n'est pas la même pour tous les types d'infractions. En particulier, les violences sexuelles étant très sous-déclarées et leur augmentation enregistrée étant quasiment uniquement due à la hausse des déclarations (au vue des enquêtes de victimation), on préférera les traiter à part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fort de ces remarques, nous allons, dans cette section, calculer les 8 indicateurs présentés à partir des 107 catégories à notre disposition. On utilise pour cela la section méthodologie du bilan de 2023 pour savoir quels index composent quelles catégories. Notons que tous les index ne sont pas utilisés, certaines infractions ne correspondant pas à ce qu'on considère usuellement comme phénomène délinquant (criminalité en col blanc, atteintes aux intérêts fondamentaux de la nation, fraude fiscale entre autres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des indicateurs de délinquance et infractions associées \n",
    "mapping = {\n",
    "    \"Homicides\": [1, 2, 3, 6, 51],\n",
    "    \"Tentatives d'homicides\": [4, 5],\n",
    "    \"Coups et blessures volontaires\": [7, 13],\n",
    "    \"Violences sexuelles\": [45, 46, 47, 48, 49, 50],\n",
    "    \"Vols avec violence\": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
    "    \"Vols sans violence\": [27, 28, 29, 30, 32, 42, 43, 34, 35, 36, 37, 38, 62, 63, 65, 66, 67, 68],\n",
    "    \"Stupéfiants\": [56, 57, 58, 59],\n",
    "    \"Escroquerie\": [91, 86, 89, 90, 92],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des indicateurs et stockage dans les DateFrames\n",
    "\n",
    "# Listes pour stocker les indicateurs\n",
    "indicateurs_dep = []  # Niveau départemental\n",
    "indicateurs_fr = []  # Niveau national\n",
    "\n",
    "# Boucle qui permet de parcourir les DataFrames pour chaque indicateur\n",
    "for indicateur, infractions in mapping.items():\n",
    "\n",
    "    # On ne conserve que les lignes avec les infractions correspondant à l'indicateur\n",
    "    df_dep_filtre = df_dep_bis[df_dep_bis['Index'].isin(infractions)] \n",
    "    df_nat_filtre = df_nat_bis[df_nat_bis['Index'].isin(infractions)] \n",
    "\n",
    "    # Somme des occurences d'infractions par zone géographique et par date\n",
    "    somme_ind_dep = (df_dep_filtre.groupby([\"Année\", \"Département\"])[\"Nombre\"].sum()\n",
    "        .reset_index() # Pour éviter que le groupby modifie l'index du DataFrame\n",
    "    )\n",
    "    somme_ind_nat = (df_nat_filtre.groupby([\"Date\", \"Zone\"])[\"Nombre\"].sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Ajouter une colonne pour libeller les indicateurs\n",
    "    somme_ind_dep[\"Indicateur\"] = indicateur\n",
    "    somme_ind_nat[\"Indicateur\"] = indicateur\n",
    "\n",
    "    # Ajouter les colonnes de libellé et de sommes au résultat\n",
    "    indicateurs_dep.append(somme_ind_dep)\n",
    "    indicateurs_fr.append(somme_ind_nat)\n",
    "\n",
    "    # Population à date et zone géographique donnée \n",
    "    pop_dep_ind = (df_dep_filtre.groupby([\"Année\", \"Département\"])[\"Population\"].first())\n",
    "    pop_nat_ind = (df_nat_filtre.groupby([\"Date\", \"Zone\"])[\"Population\"].first())\n",
    "\n",
    "\n",
    "# Combiner les résultats pour les indicateurs\n",
    "df_indicateurs_dep = pd.concat(indicateurs_dep, ignore_index=True) \n",
    "df_indicateurs_nat = pd.concat(indicateurs_fr, ignore_index=True)\n",
    "\n",
    "# Ajout des données de population départementale\n",
    "df_indicateurs_dep = df_indicateurs_dep.merge(\n",
    "    pop_dep_ind,\n",
    "    on=[\"Année\", \"Département\"],  \n",
    "    how=\"left\"                   \n",
    ")\n",
    "\n",
    "df_indicateurs_nat = df_indicateurs_nat.merge(\n",
    "    pop_nat_ind,\n",
    "    on=[\"Date\", \"Zone\"],  \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Réorganisation des colonnes \n",
    "df_indicateurs_dep = df_indicateurs_dep[[\"Année\", \"Département\", \"Indicateur\", \"Nombre\", \"Population\"]]\n",
    "df_indicateurs_nat = df_indicateurs_nat[[\"Date\", \"Zone\", \"Indicateur\", \"Nombre\", \"Population\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ensuite une colonne avec les taux de délinquance pour chaque indicateurs en divisant les colonnes 'Nombre' et 'Population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans la base départementale\n",
    "df_indicateurs_dep[\"Taux (/10 000)\"] = (df_indicateurs_dep[\"Nombre\"] / df_indicateurs_dep[\"Population\"]) * 10000\n",
    "\n",
    "# Dans la base nationale\n",
    "df_indicateurs_nat[\"Population\"] = pd.to_numeric(df_indicateurs_nat[\"Population\"], errors='coerce') # Gérer les problèmes de formats de données\n",
    "df_indicateurs_nat[\"Taux (/10 000)\"] = (df_indicateurs_nat[\"Nombre\"] / df_indicateurs_nat[\"Population\"]) * 10 # La population est en milliers d'habitants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Autres variables<a class=\"anchor\" id=\"section23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite quelques variables permettant de classifier temporellement les données (l'année, le mois, la saison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des colonnes 'Date' au format datetime dans la base nationale\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_indicateurs_nat['Date']):\n",
    "    df_indicateurs_nat['Date'] = pd.to_datetime(df_indicateurs_nat['Date'].str.extract(r'_(\\d{4})_(\\d{2})')[0] + '-' +\n",
    "                             df_indicateurs_nat['Date'].str.extract(r'_(\\d{4})_(\\d{2})')[1], format='%Y-%m')\n",
    "\n",
    "# Ajout d'une colonne indiquant l'année, le mois pour la base nationale\n",
    "df_indicateurs_nat['Année'] = df_indicateurs_nat['Date'].dt.year\n",
    "df_indicateurs_nat['Mois'] = df_indicateurs_nat['Date'].dt.month\n",
    "\n",
    "# Dictionnaire des saisons avec les mois correspondants\n",
    "saisons = {\n",
    "    'Hiver': [12, 1, 2],\n",
    "    'Printemps': [3, 4, 5],\n",
    "    'Été': [6, 7, 8],\n",
    "    'Automne': [9, 10, 11]\n",
    "}\n",
    "\n",
    "# Ajouter une colonne 'Saison' au dataframe en fonction du mois\n",
    "def get_saison(mois):\n",
    "    for saison, mois_list in saisons.items():\n",
    "        if mois in mois_list:\n",
    "            return saison\n",
    "    return None  # Retourner None si le mois n'est pas trouvé (devrait pas arriver)\n",
    "\n",
    "df_indicateurs_nat['Saison'] = df_indicateurs_nat['Mois'].apply(get_saison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de permettre de visualiser des évolutions d'indice, on crée une colonne de taux relatifs où on normalise tous les taux par la valeur en 1996. On n'ajoute cette colonne qu'au DataFrame national, car au niveau départemental les taux sont régulièrement à zéro pour les départements peu peuplés, ce qui donne beaucoup de valeurs non définie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier les données par indicateur et par date\n",
    "df_indicateurs_nat = df_indicateurs_nat.sort_values(by=['Indicateur', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# Normaliser les valeurs à 1 pour la première valeur de chaque indicateur\n",
    "df_indicateurs_nat['Taux relatif'] = df_indicateurs_nat.groupby('Indicateur')['Taux (/10 000)'].transform(lambda x: x / x.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouts de variables de contrôle pour une future modélisation<a class=\"anchor\" id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Densité urbaine<a class=\"anchor\" id=\"section31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le but d'effectuer une modélisation économétrique permettant d'évaluer l'effet de la législation sur les taux de criminalité, on a réfléchi à des variables de contrôle à inclure dans notre régression. La densité (comme proxy de la densité urbaine) nous semblait être un choix intéressant puisqu'on pourrait dresser l'hypothèse que les fortes densités peuvent favoriser l'émergence de violences interpersonnelles tout en compliquant l'action des forces de l'ordre.\n",
    "\n",
    "Dans l'optique de réaliser une régression de panel, nous avons jugé qu'il s'agissait d'une bonne variable pour distinguer les départements entre eux notamment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la mesure où l'on a déjà récupéré les estimations de populations à l'échelle nationale et départementale, on n'a simplement qu'à récupérer les superficies cadastrales en km2 (celle utilisée par l'INSEE) des différents départements français en scrapant la page wikipédia correspondante ([juste là](https://fr.wikipedia.org/wiki/Superficie_des_d%C3%A9partements_fran%C3%A7ais)).\n",
    "\n",
    "Les informations recherchées se trouvent sur le premier tableau de la page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_superficie = (\n",
    "    \"https://fr.wikipedia.org/wiki/Superficie_des_d%C3%A9partements_fran%C3%A7ais\"\n",
    ")\n",
    "\n",
    "request_text = requests.get(url_superficie).content\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "tableau_superficies=page.find(\"table\")\n",
    "\n",
    "print(tableau_superficies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tableau est assez riche, on veut seulement en récupérer les codes de département et les superficies cadastrales ce qui exige encore quelques manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver toutes les lignes du tableau\n",
    "table_body = tableau_superficies.find(\"tbody\")\n",
    "rows = table_body.find_all(\"tr\")\n",
    "\n",
    "# On parcours les lignes et on mets le texte dans un dictionnaire\n",
    "dico_superficies = dict()\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    if len(cols) > 0:\n",
    "        dico_superficies[cols[0]] = cols[1:]\n",
    "\n",
    "# Visualisation\n",
    "dico_superficies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du fait de la structure assez complexe du tableau, toutes les clés ne sont pas des codes de départements, on trie le dictionnaire pour qu'il ne reste bien que les codes de département en faisant attention au cas de la Corse qui ne représente qu'une entrée dans le tableau de wikipédia mais qui contient bien deux départements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_superficie = {\n",
    "    key: value\n",
    "    for key, value in dico_superficies.items()\n",
    "    if (key.isdigit() and int(key) <= 95) or key == '20[Note 2]' or key == 'Bastia' \n",
    "}\n",
    "\n",
    "dico_superficie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant faire de notre dictionnaire un DataFrame et effectuer quelques dernières opérations de tri pour ne conserver que la variable d'intérêt. A nouveau, les données concernant la Corse réclament un peu d'attention..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du DataFrame\n",
    "data_superficies = pd.DataFrame.from_dict(dico_superficie, orient=\"index\")\n",
    "\n",
    "# Mise à jour les libellé et les structures de ligne pour les départements corses\n",
    "data_superficies = data_superficies.replace({\n",
    "    \"Corse\": \"Corse-du-Sud\",  \n",
    "    '1\\xa0351,14': \"Haute-Corse\"  \n",
    "})\n",
    "\n",
    "ligne_bastia = data_superficies.loc['Bastia'] \n",
    "ligne_bastia[2], ligne_bastia[5] = ligne_bastia[5], ligne_bastia[2]\n",
    "data_superficies.loc['Bastia'] = ligne_bastia\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "data_superficies = data_superficies.drop(columns=[1, 2, 3, 4, 6, 7]) \n",
    "\n",
    "# Adaptation du format des superficies\n",
    "data_superficies[\"Superficie (km2)\"] = (\n",
    "    data_superficies[5]\n",
    "    .str.replace(r\"\\s+\", \"\", regex=True) \n",
    "    .str.extract(r\"^(\\d+)\", expand=False) \n",
    "    .astype(int) \n",
    ")\n",
    "data_superficies = data_superficies.drop(columns=[5]) \n",
    "\n",
    "# Ajouter une colonne 'Département' qui donne les codes de département\n",
    "data_superficies['Département'] = data_superficies.index\n",
    "\n",
    "data_superficies = data_superficies.replace({\n",
    "    \"20[Note 2]\": \"2A\",  \n",
    "    'Bastia': \"2B\"  \n",
    "})\n",
    "\n",
    "data_superficies.rename(columns={ 0: 'Nom Département'}, inplace=True)\n",
    "\n",
    "# Visualisation\n",
    "data_superficies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant ajouter cette variable à notre base départementale pour calculer les densités de population qu'on considère un proxy satisfaisant de la densité urbaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure sur la colonne \"Département\"\n",
    "df_indicateurs_dep = pd.merge(df_indicateurs_dep, data_superficies, on='Département', how='inner')\n",
    "\n",
    "# Création de la variable \"Densité\"\n",
    "df_indicateurs_dep['Densité'] = df_indicateurs_dep['Population'] / df_indicateurs_dep['Superficie (km2)']\n",
    "\n",
    "# Visualisation du résultat\n",
    "df_indicateurs_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolution du taux de pauvreté<a class=\"anchor\" id=\"section32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le caractère criminogène de la pauvreté est largement documenté, nous avons donc également décidé d'inclure cette variable comme variable de contrôle. On a récupéré, toujours sur le site de l'INSEE ([là, plus précisément](https://www.insee.fr/fr/statistiques/3564980?utm_source=chatgpt.com#tableau-figure1)), l'évolution du taux de pauvreté en France défini comme le fait d'être en dessous de 60% du niveau de vie médian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de téléchargement du fichier Excel\n",
    "url = \"https://www.insee.fr/fr/statistiques/fichier/3564980/reve-pauv-intensite.xlsx\"\n",
    "\n",
    "# Dossier de destination\n",
    "destination = \"/home/onyxia/work/Python-pour-la-data-science-2A/data/data_pop\"\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Chemin du fichier Excel téléchargé\n",
    "fichier_excel = os.path.join(destination, \"reve_pauv_intensite.xlsx\")\n",
    "\n",
    "# Téléchargement du fichier Excel\n",
    "print(\"Téléchargement en cours...\")\n",
    "response = requests.get(url, stream=True)\n",
    "with open(fichier_excel, \"wb\") as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "print(\"Téléchargement terminé:\", fichier_excel)\n",
    "\n",
    "# Vérification de l'existence du fichier téléchargé\n",
    "if os.path.exists(fichier_excel):\n",
    "    print(\"Fichier téléchargé avec succès.\")\n",
    "else:\n",
    "    print(\"Le téléchargement a échoué.\")\n",
    "\n",
    "# Chargement du fichier Excel en DataFrame\n",
    "print(\"Chargement du fichier Excel en DataFrame...\")\n",
    "df = pd.read_excel(fichier_excel)\n",
    "\n",
    "# Supprimer le fichier Excel une fois que le DataFrame est chargé\n",
    "os.remove(fichier_excel)\n",
    "print(f\"Le fichier {fichier_excel} a été supprimé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes inutiles\n",
    "df_pauvreté = df[df['Intensité de la pauvreté'].isin(['Indicateur', 'Intensité de la pauvreté5 (en %)'])]\n",
    "df_pauvreté = df_pauvreté.drop(10)\n",
    "\n",
    "# Modification des colonnes concernant l'année (en double à cause d'un changement de méthodologie)\n",
    "df_pauvreté = df_pauvreté.drop('Unnamed: 27', axis=1)\n",
    "df_pauvreté= df_pauvreté.replace(\"20203 4\", 2020.0, )\n",
    "\n",
    "# On renomme les différentes colonnes avec les années correspondantes \n",
    "annees = df_pauvreté.iloc[0, 1:].values.astype(int)\n",
    "df_pauvreté.columns = ['Année'] + list(annees) \n",
    "df_pauvreté = df_pauvreté.drop(2)\n",
    "\n",
    "# On transforme le Dataframe pour obtenir un format long plutôt que wide\n",
    "df_pauvreté_bis = df_pauvreté.melt( var_name='Année', value_name='Taux de pauvreté (%)' )\n",
    "df_pauvreté_bis = df_pauvreté_bis.drop([0, 16, 19]) # Suppression de doublons\n",
    "df_pauvreté_bis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_pauvreté_bis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute maintenant cette nouvelle variable à la base nationale. Nous n'avons pas réussi à trouver ces données en open data à l'échelle départementale malheureusement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure sur les annnées\n",
    "df_indicateurs_nat = pd.merge(df_indicateurs_nat, df_pauvreté_bis, on='Année', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation 1\n",
    "df_indicateurs_nat.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation 2\n",
    "df_indicateurs_dep.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des tableaux de données finalisés<a class=\"anchor\" id=\"section4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information requise pour la connexion au Bucket de Anh Linh sur le MinIO Client cloud\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "MY_BUCKET = \"anhlinh\"\n",
    "fs.ls(MY_BUCKET)\n",
    "\n",
    "# Export des DataFrame finalisés dans le cloud\n",
    "FILE_PATH_OUT_DEP = f\"{MY_BUCKET}/diffusion/df_indicateurs_dep.csv\"\n",
    "with fs.open(FILE_PATH_OUT_DEP, \"w\") as file_out_dep:\n",
    "    df_indicateurs_dep.to_csv(file_out_dep)\n",
    "\n",
    "FILE_PATH_OUT_NAT = f\"{MY_BUCKET}/diffusion/df_indicateurs_nat.csv\"\n",
    "with fs.open(FILE_PATH_OUT_NAT, \"w\") as file_out_nat:\n",
    "    df_indicateurs_nat.to_csv(file_out_nat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls(f\"{MY_BUCKET}/diffusion\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
